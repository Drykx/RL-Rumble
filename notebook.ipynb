{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a23794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858e8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Feedforward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Convert obs to tensor\n",
    "        if isinstance(obs, np.ndarray):\n",
    "            obs = torch.tensor(obs, dtype = torch.float)\n",
    "        # Forward pass\n",
    "        obs = F.relu(self.fc1(obs))\n",
    "        obs = self.fc2(obs)\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca771873",
   "metadata": {},
   "source": [
    "**Architectural choices:**\n",
    "\n",
    "- Define the feedforwardNN class independently and inherit it from nn.Module.\n",
    "\n",
    "- have a specific _init_hyperparameters method to initialize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9362095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO():\n",
    "\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        self.obs_dim = env.observation_space.shape[0]\n",
    "        self.act_dim = env.action_space.shape[0]\n",
    "\n",
    "        self.init_parameters = self._init_hyperparameters()\n",
    "\n",
    "        self.actor = Feedforward(self.obs_dim,self.act_dim)\n",
    "        self.critic = Feedforward(self.obs_dim,1)\n",
    "\n",
    "    def _init_hyperparameters(self):\n",
    "\n",
    "        self.timesteps_per_batch = 4000\n",
    "        self.max_timesteps_per_episode = 1000\n",
    "        self.gamma = 0.95\n",
    "\n",
    "    def rollout(self):\n",
    "        \"\"\"Generate time_steps_per_batch in multiple episodes each \n",
    "        of maximum length max_timesteps_per_episode\n",
    "        \"\"\"\n",
    "        # Batch data\n",
    "        batch_obs = []\n",
    "        batch_acts = []\n",
    "        batch_log_probs = []\n",
    "        batch_rews = []\n",
    "        batch_rgts = [] # Batch rewards-to-go\n",
    "        batch_lens = [] # Episiodic length in batch\n",
    "\n",
    "        current_timesteps = 0\n",
    "        while current_timesteps < self.timesteps_per_batch:\n",
    "            \n",
    "            # Initialization\n",
    "            ep_rews = [] # special format for rgts\n",
    "            obs = self.env.reset()\n",
    "            done = False\n",
    "\n",
    "            for ep_t in range(self.max_timesteps_per_episode):\n",
    "                # Collect observations\n",
    "                batch_obs.append(obs)\n",
    "                action, log_probs = self.get_action(obs)\n",
    "                obs, rew, done, _ = self.env.step(action)\n",
    "\n",
    "                # Collect reward, action and log_prob\n",
    "                ep_rews.append(rew)\n",
    "                batch_acts.append(action)\n",
    "                batch_log_probs.append(log_probs)\n",
    "\n",
    "                current_timesteps += 1\n",
    "                if done: break # If the agent completed the task finish\n",
    "\n",
    "            # Collect episodic length and rewards\n",
    "            current_timesteps += ep_t\n",
    "            batch_rews.append(ep_rews)            \n",
    "            batch_lens.append(ep_t + 1)\n",
    "\n",
    "        # Transform into desired format (Torch)\n",
    "        batch_obs       = torch.tensor(batch_obs, dtype = torch.float)\n",
    "        batch_acts      = torch.tensor(batch_acts, dtype = torch.float)\n",
    "        batch_log_probs = torch.tensor(batch_log_probs, dtype = torch.float)\n",
    "\n",
    "        batch_rgts = self.compute_rgts(batch_rews)\n",
    "\n",
    "        return batch_obs,batch_acts, batch_log_probs, batch_rgts, batch_lens\n",
    "\n",
    "    def compute_rgts(self, batch_rews: list) -> torch.Tensor:\n",
    "        \"Compute rtg per episode per batch\"\n",
    "\n",
    "        batch_rgts = []\n",
    "\n",
    "        for ep_rews in batch_rews:\n",
    "            ep_rgts = []\n",
    "            discounted_sum = 0\n",
    "            for rew in reversed(batch_rews):\n",
    "                discounted_sum = rew + self.gamma * rew\n",
    "                ep_rgts.insert(0,discounted_sum) # We need the history of rgts at each time steps\n",
    "            \n",
    "            batch_rgts.extend(ep_rgts)\n",
    "        \n",
    "        return torch.tensor(batch_rgts, dtype = torch.float)\n",
    "\n",
    "    def __init(self, env, stdev: float):\n",
    "        \"Create diagonal covariance matrix of stdev to sample actions from state\"\n",
    "\n",
    "        self.cov_vect = torch.full((self.act_dim, ), fill_value = stdev) # standard deviation vector\n",
    "        self.cov_mat = torch.diag(self.cov_vect) # [act_dim, act_dim]\n",
    "\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        \"Generate an action as a sample of a Multivariate normal distribution\"\n",
    "        # Query actor network for an action\n",
    "        mean = self.actor(obs) # Call NN (self.actor.forward(obs))\n",
    "        dist = MultivariateNormal(mean, self.cov_mat)\n",
    "\n",
    "        # Generate sample from the distribution\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "\n",
    "        return action.detach().nump(), log_prob.detach()\n",
    "\n",
    "    def learn(self, total_timesteps): \n",
    "\n",
    "        current_timestep = 0\n",
    "\n",
    "        while current_timestep < total_timesteps:\n",
    "\n",
    "            batch_obs,batch_acts, batch_log_probs, batch_rgts, batch_lens = self.rollout()\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
