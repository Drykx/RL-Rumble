{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a23794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858e8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Feedforward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        # Convert obs to tensor\n",
    "        if isinstance(obs, np.ndarray):\n",
    "            obs = torch.tensor(obs, dtype = torch.float)\n",
    "        # Forward pass\n",
    "        obs = F.relu(self.fc1(obs))\n",
    "        obs = self.fc2(obs)\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO(nn.module):\n",
    "\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        self.obs_dim = env.observation_space.shape[0]\n",
    "        self.act_dim = env.action_space.shape[0]\n",
    "\n",
    "        self.init_parameters = self._init_hyperparameters()\n",
    "\n",
    "        self.actor = Feedforward(self.obs_dim,self.act_dim)\n",
    "        self.critic = Feedforward(self.obs_dim,1)\n",
    "\n",
    "    def _init_hyperparameters(self):\n",
    "        self.timesteps_per_batch = 4000\n",
    "        self.max_timesteps_per_episode = 1600 \n",
    "\n",
    "    def rollout(self):\n",
    "        # Batch data\n",
    "        batch_obs = []\n",
    "        batch_acts = []\n",
    "        batch_log_probs = []\n",
    "        batch_rews = []\n",
    "        batch_rgts = [] # Batch rewards-to-go\n",
    "        batch_lens = [] # Episiodic length in batch\n",
    "\n",
    "    def learn(self, total_timesteps): \n",
    "        current_timesteps = 0\n",
    "        while current_timesteps < total_timesteps:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
