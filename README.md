#  🤖 RL-Rumble

A personal project to implement and benchmark three foundational reinforcement learning algorithms from scratch:

- **Proximal Policy Optimization (PPO)**
- **Variational Free Energy (VFE)**
- **Soft Actor-Critic (SAC)**

The goal is to understand their core mechanics, compare their performance, and build a unified framework for evaluating RL methods across diverse environments.

---

## ✅ To-Do List

### 🏋️ PPO (Proximal Policy Optimization)
- [ ] Improve performance metrics (e.g., average reward, stability)
- [ ] Evaluate across multiple seeds and environments

### 🧠 VFE – Variational Free Energy / Active Inference
- [ ] Design generative and recognition models
- [ ] Implement inference and action selection loop
- [ ] Validate behavior in simple discrete environments
- [ ] Extend to continuous action environments (optional/advanced)

### 🔥 SAC – Soft Actor-Critic
- [ ] Build full SAC pipeline (actor, twin critics, entropy regularization)
- [ ] Integrate replay buffer and soft target updates
- [ ] Benchmark in continuous control tasks (e.g. Pendulum, HalfCheetah)
---

## 📊 Coming Soon
- Benchmark results and learning curves
- Agent behavior visualizations
- A unified interface for evaluating algorithm performance

Stay tuned as each agent comes online!
